import pandas as pd
from sqlalchemy import create_engine
from sqlalchemy.engine import URL
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Параметры подключения
connection_url = URL.create(
    "postgresql",
    username='praktikum_student',
    password='Sdf4$2;d-d30pp',
    host='rc1b-wcoijxj3yxfsf3fs.mdb.yandexcloud.net',
    port=6432,
    database='data-analyst-afisha'
)

# Создаем engine и выполняем запрос
engine = create_engine(connection_url)

query = """
SELECT 
    p.user_id,
    p.device_type_canonical,
    p.order_id,
    p.created_dt_msk AS order_dt,
    p.created_ts_msk AS order_ts,
    p.currency_code,
    p.revenue,
    p.tickets_count,
    (p.created_dt_msk - LAG(p.created_dt_msk) OVER (PARTITION BY p.user_id ORDER BY p.created_ts_msk)) AS days_since_prev,
    p.event_id,
    p.service_name,
    e.event_type_main,
    r.region_name,
    c.city_name
FROM 
    afisha.purchases p
LEFT JOIN afisha.events e ON p.event_id = e.event_id
LEFT JOIN afisha.city c ON e.city_id = c.city_id
LEFT JOIN afisha.regions r ON c.region_id = r.region_id
ORDER BY p.user_id, p.created_ts_msk;
"""

df = pd.read_sql_query(query, engine)
engine.dispose()

df.head()

# Основная информация о данных
display(f"Общий объем данных: {df.shape[0]} строк, {df.shape[1]} столбцов\n")

display("1. Информация о типах данных и пропусках:")

display(df.info())

display("2. Пропущенные значения по столбцам:")

display(df.isnull().sum())

display("3. Уникальные значения в категориальных полях:")

display(f"Уникальных пользователей: {df['user_id'].nunique()}")
display(f"Уникальных заказов: {df['order_id'].nunique()}")
display(f"Уникальных мероприятий: {df['event_id'].nunique()}")
display(f"Типы устройств: {df['device_type_canonical'].unique()}")
display(f"Валюты: {df['currency_code'].unique()}")
display(f"Типы мероприятий: {df['event_type_main'].unique()}")
display(f"Регионы: {df['region_name'].unique()}")
display(f"Города: {df['city_name'].unique()}")


display("4. Временной диапазон данных:")

display(f"Минимальная дата заказа: {df['order_dt'].min()}")
display(f"Максимальная дата заказа: {df['order_dt'].max()}")
display(f"Минимальная дата/время заказа: {df['order_ts'].min()}")
display(f"Максимальная дата/время заказа: {df['order_ts'].max()}")

display("5. Статистика по числовым полям:")

display(df[['revenue', 'tickets_count', 'days_since_prev']].describe())

# Загрузка курса тенге
tenge_df = pd.read_csv('https://code.s3.yandex.net/datasets/final_tickets_tenge_df.csv')
tenge_df['data'] = pd.to_datetime(tenge_df['data'])

# Добавляем дату заказа без времени
df['order_date'] = df['order_dt'].dt.date
df['order_date'] = pd.to_datetime(df['order_date'])

# Объединяем с курсом валют
df = pd.merge(df, tenge_df[['data', 'curs']], 
              left_on='order_date', right_on='data', how='left')

# Конвертируем тенге в рубли (курс за 100 тенге, делим на 100)
df['curs'] = df['curs'] / 100

# Создаем revenue_rub
df['revenue_rub'] = df.apply(lambda row: 
    row['revenue'] if row['currency_code'] == 'rub' 
    else row['revenue'] * row['curs'] if pd.notnull(row['curs']) 
    else row['revenue'], axis=1)

# Удаляем вспомогательные колонки
df = df.drop(['data', 'order_date', 'curs'], axis=1)

display("Конвертация завершена. Столбец revenue_rub создан.")
display("\nКолонки в DataFrame:")
display(df.columns.tolist())
display(f"\nПервые 5 строк с revenue_rub:")
display(df[['currency_code', 'revenue', 'revenue_rub']].head())
display(f"\nРаспределение по валютам:")
display(df['currency_code'].value_counts())
display(f"\nСтатистика по revenue_rub:")
display(df['revenue_rub'].describe())

# Проверка пропусков
display(df.isnull().sum())

#Преобразование типов данных
# days_since_prev преобразуем из timedelta в количество дней (float)
if df['days_since_prev'].dtype == 'timedelta64[ns]':
    df['days_since_prev_days'] = df['days_since_prev'].dt.total_seconds() / (24 * 3600)
    df['days_since_prev_days'] = df['days_since_prev_days'].astype('float32')
    display(f"days_since_prev преобразован в дни. Диапазон: {df['days_since_prev_days'].min():.1f} - {df['days_since_prev_days'].max():.1f} дней")
else:
    display("days_since_prev уже преобразован")

# Оптимизация числовых типов
df['tickets_count'] = df['tickets_count'].astype('int16')
df['order_id'] = df['order_id'].astype('int32')
df['event_id'] = df['event_id'].astype('int32')
df['revenue_rub'] = df['revenue_rub'].astype('float32')

display("\nТипы данных после оптимизации:")
display(df.dtypes)


# Изучение ключевых столбцов

categorical_cols = ['device_type_canonical', 'currency_code', 'service_name', 
                    'event_type_main', 'region_name', 'city_name']

for col in categorical_cols:
    print(f"\n{col}:")
    print(f"  Уникальных значений: {df[col].nunique()}")
    if df[col].nunique() <= 15:
        print(f"  Значения: {sorted(df[col].unique())}")
    else:
        print(f"  Первые 10 значений: {sorted(df[col].unique())[:10]}")


# Проверка числовых данных на выбросы

numeric_cols = ['revenue_rub', 'tickets_count']
percentiles = [0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99, 0.999]

for col in numeric_cols:
    display(f"\n{col}:")
    display(df[col].describe())
    display("\n  Перцентили:")
    for p in percentiles:
        display(f"    {p*100:.1f}%: {df[col].quantile(p):.2f}")
    
    # Проверка на отрицательные значения
    negative_count = (df[col] < 0).sum()
    if negative_count > 0:
        display(f"  Отрицательных значений: {negative_count}")
        display(f"  Минимальное значение: {df[col].min():.2f}")


# Визуальный анализ распределения и выбросов
fig, axes = plt.subplots(2, 3, figsize=(15, 10))

# Гистограмма revenue_rub
axes[0, 0].hist(df['revenue_rub'].dropna(), bins=50, edgecolor='black', alpha=0.7)
axes[0, 0].set_title('Распределение revenue_rub')
axes[0, 0].set_xlabel('Выручка, руб')
axes[0, 0].set_ylabel('Частота')

# Логарифмированная гистограмма revenue_rub
axes[0, 1].hist(df['revenue_rub'][df['revenue_rub'] > 0].dropna(), 
                bins=50, edgecolor='black', alpha=0.7, log=True)
axes[0, 1].set_title('Лог. распределение revenue_rub (revenue_rub > 0)')
axes[0, 1].set_xlabel('Выручка, руб (лог)')
axes[0, 1].set_ylabel('Частота (лог)')

# Boxplot revenue_rub
axes[0, 2].boxplot(df['revenue_rub'].dropna())
axes[0, 2].set_title('Boxplot revenue_rub')
axes[0, 2].set_ylabel('Выручка, руб')

# Гистограмма tickets_count
axes[1, 0].hist(df['tickets_count'].dropna(), bins=30, edgecolor='black', alpha=0.7)
axes[1, 0].set_title('Распределение tickets_count')
axes[1, 0].set_xlabel('Количество билетов')
axes[1, 0].set_ylabel('Частота')

# Boxplot tickets_count
axes[1, 1].boxplot(df['tickets_count'].dropna())
axes[1, 1].set_title('Boxplot tickets_count')
axes[1, 1].set_ylabel('Количество билетов')

# Scatter plot revenue_rub vs tickets_count
axes[1, 2].scatter(df['tickets_count'], df['revenue_rub'], alpha=0.3, s=10)
axes[1, 2].set_title('revenue_rub vs tickets_count')
axes[1, 2].set_xlabel('Количество билетов')
axes[1, 2].set_ylabel('Выручка, руб')

plt.tight_layout()
plt.show()


# Фильтрация выбросов по 99 перцентилю для revenue_rub
display("Фильтрация выбросов:")
revenue_99_percentile = df['revenue_rub'].quantile(0.99)
display(f"99 перцентиль revenue_rub: {revenue_99_percentile:.2f} руб")

# Количество записей выше 99 перцентиля
outliers_count = (df['revenue_rub'] > revenue_99_percentile).sum()
display(f"Записей выше 99 перцентиля: {outliers_count} ({outliers_count/len(df)*100:.2f}%)")

# Фильтрация данных
df_clean = df[df['revenue_rub'] <= revenue_99_percentile].copy()
display(f"Размер данных до фильтрации: {df.shape}")
display(f"Размер данных после фильтрации: {df_clean.shape}")
display(f"Удалено записей: {len(df) - len(df_clean)} ({100*(len(df)-len(df_clean))/len(df):.2f}%)")

# Проверка tickets_count на аномалии
tickets_99_percentile = df_clean['tickets_count'].quantile(0.99)
display(f"\n99 перцентиль tickets_count: {tickets_99_percentile}")
tickets_outliers = (df_clean['tickets_count'] > tickets_99_percentile).sum()
display(f"Записей выше 99 перцентиля tickets_count: {tickets_outliers}")


# Визуальный анализ распределения и выбросов


fig, axes = plt.subplots(2, 3, figsize=(15, 10))

# Гистограмма revenue_rub
axes[0, 0].hist(df['revenue_rub'].dropna(), bins=50, edgecolor='black', alpha=0.7)
axes[0, 0].set_title('Распределение revenue_rub')
axes[0, 0].set_xlabel('Выручка, руб')
axes[0, 0].set_ylabel('Частота')

# Логарифмированная гистограмма revenue_rub
axes[0, 1].hist(df['revenue_rub'][df['revenue_rub'] > 0].dropna(), 
                bins=50, edgecolor='black', alpha=0.7, log=True)
axes[0, 1].set_title('Лог. распределение revenue_rub (revenue_rub > 0)')
axes[0, 1].set_xlabel('Выручка, руб (лог)')
axes[0, 1].set_ylabel('Частота (лог)')

# Boxplot revenue_rub
axes[0, 2].boxplot(df['revenue_rub'].dropna())
axes[0, 2].set_title('Boxplot revenue_rub')
axes[0, 2].set_ylabel('Выручка, руб')

# Гистограмма tickets_count
axes[1, 0].hist(df['tickets_count'].dropna(), bins=30, edgecolor='black', alpha=0.7)
axes[1, 0].set_title('Распределение tickets_count')
axes[1, 0].set_xlabel('Количество билетов')
axes[1, 0].set_ylabel('Частота')

# Boxplot tickets_count
axes[1, 1].boxplot(df['tickets_count'].dropna())
axes[1, 1].set_title('Boxplot tickets_count')
axes[1, 1].set_ylabel('Количество билетов')

# Scatter plot revenue_rub vs tickets_count
axes[1, 2].scatter(df['tickets_count'], df['revenue_rub'], alpha=0.3, s=10)
axes[1, 2].set_title('revenue_rub vs tickets_count')
axes[1, 2].set_xlabel('Количество билетов')
axes[1, 2].set_ylabel('Выручка, руб')

plt.tight_layout()
plt.show()

# Проверка на дубликаты

# Полные дубликаты
full_dup = df.duplicated().sum()
display(f"Полные дубликаты: {full_dup}")

# Дубликаты order_id (критично)
order_dup = df['order_id'].duplicated().sum()
display(f"Дубликаты order_id: {order_dup}")

# 3. Логические дубликаты
logic_dup = df.duplicated(subset=['user_id', 'order_ts', 'revenue_rub']).sum()
display(f"Логические дубликаты (user+время+сумма): {logic_dup}")

# 4. Проверка по минуте (потенциальные дубли)
df['order_minute'] = df['order_ts'].dt.floor('T')
minute_dup = df.duplicated(subset=['user_id', 'order_minute', 'tickets_count']).sum()
display(f"Потенциальные дубли (user+минута+билеты): {minute_dup}")

# 5. Неявные дубли в городах (простые проверки)
cities = df['city_name'].str.lower().str.replace('ё', 'е').unique()
# Ищем одинаковые города без суффиксов
city_base = [city.split()[0][:8] if ' ' in city else city[:8] for city in cities]
from collections import Counter
city_counts = Counter(city_base)
implicit_city_dup = sum(1 for count in city_counts.values() if count > 1)
display(f"Города с похожими названиями: {implicit_city_dup}")

# 6. Проверка данных
display(f"\nДругие проверки:")
display(f"Отрицательная выручка: {(df['revenue_rub'] < 0).sum()}")
display(f"Нулевые билеты: {(df['tickets_count'] <= 0).sum()}")
display(f"Несоответствие дат: {(df['order_dt'].dt.date != df['order_ts'].dt.date).sum()}")

# Удаляем временную колонку
df = df.drop('order_minute', axis=1, errors='ignore')

# Решение

# Отрицательная выручка
neg_revenue = df[df['revenue_rub'] < 0]
display(f"1. Отрицательная выручка ({len(neg_revenue)} записей):")

# Анализ отрицательных значений
display(f"   Минимальное значение: {neg_revenue['revenue_rub'].min():.2f}")
display(f"   Среднее отрицательное: {neg_revenue['revenue_rub'].mean():.2f}")
display(f"   Максимальное отрицательное: {neg_revenue['revenue_rub'].max():.2f}")

# Решение: заменить на 0 или модуль (в зависимости от природы)
df['revenue_rub'] = df['revenue_rub'].clip(lower=0)  # Заменяем отрицательные на 0
display(f"   → Отрицательные значения заменены на 0")

# Логические дубликаты (50 записей)
display(f"\n2. Логические дубликаты (50 записей):")
# Оставляем только первую запись из дубликатов
df = df.drop_duplicates(subset=['user_id', 'order_ts', 'revenue_rub'], keep='first')
display(f"   → Удалены дубликаты, оставлена первая запись")

# Потенциальные дубликаты (4012 записей) - нужно исследовать
display(f"\n3. Потенциальные дубликаты (покупки в одну минуту):")
# Создаем временную метку для группировки
df['order_minute'] = df['order_ts'].dt.floor('T')

# Считаем покупки пользователей в одну минуту
dup_counts = df.groupby(['user_id', 'order_minute', 'tickets_count']).size()
multi_purchases = dup_counts[dup_counts > 1].sum() - len(dup_counts[dup_counts > 1])
display(f"   Всего потенциальных дубликатов: {multi_purchases}")

# Анализируем несколько примеров
sample_dups = df[df.duplicated(subset=['user_id', 'order_minute', 'tickets_count'], keep=False)]
if len(sample_dups) > 0:
    display(f"   Примеры (первые 2 пользователя):")
    sample_users = sample_dups['user_id'].unique()[:2]
    for user in sample_users:
        user_dups = sample_dups[sample_dups['user_id'] == user].sort_values('order_ts')
        display(f"   Пользователь {user}:")
        display(user_dups[['order_ts', 'revenue_rub', 'tickets_count', 'event_type_main']].head(3).to_string())

# Решение: оставить как есть, если это разные мероприятия
display(f"   → Оставляем как есть (возможно, разные мероприятия)")

# Города с похожими названиями
display(f"\n4. Города с похожими названиями простая нормализация: приводим к нижнему регистру и заменяем ё на е (32 группы):")
df['city_name_norm'] = df['city_name'].str.lower().str.replace('ё', 'е')

# Удаляем временные колонки
df = df.drop(['order_minute'], axis=1, errors='ignore')

display(f"\nРазмер данных после обработки: {df.shape}")
display(f"Отрицательной выручки: {(df['revenue_rub'] < 0).sum()}")
display(f"Логических дубликатов: {df.duplicated(subset=['user_id', 'order_ts', 'revenue_rub']).sum()}")

# Сортируем данные по пользователю и времени заказа
df_sorted = df.sort_values(['user_id', 'order_ts']).copy()

# Преобразуем days_since_prev в числовой формат (дни) если нужно
if df_sorted['days_since_prev'].dtype == 'timedelta64[ns]':
    df_sorted['days_since_prev_days'] = df_sorted['days_since_prev'].dt.total_seconds() / (24 * 3600)
else:
    df_sorted['days_since_prev_days'] = df_sorted['days_since_prev']

# Основные агрегации на уровне пользователя
user_profile = df_sorted.groupby('user_id').agg(
    first_order_date=('order_dt', 'min'),
    last_order_date=('order_dt', 'max'),
    total_orders=('order_id', 'count'),
    avg_revenue=('revenue_rub', 'mean'),
    avg_tickets=('tickets_count', 'mean')
).reset_index()

# Среднее время между заказами (только для пользователей с >1 заказом)
# Сначала считаем для каждого пользователя
def calculate_avg_days(group):
    if len(group) > 1:
        return group['days_since_prev_days'].mean()
    return 0

avg_days_df = df_sorted.groupby('user_id').apply(calculate_avg_days).reset_index()
avg_days_df.columns = ['user_id', 'avg_days_between']

# Объединяем с основным профилем
user_profile = pd.merge(user_profile, avg_days_df, on='user_id', how='left')

# Признаки из первого заказа
first_orders = df_sorted.drop_duplicates('user_id', keep='first').set_index('user_id')

user_profile = user_profile.set_index('user_id')
user_profile['first_order_device'] = first_orders['device_type_canonical']
user_profile['first_order_region'] = first_orders['region_name']
user_profile['first_order_partner'] = first_orders['service_name']
user_profile['first_order_genre'] = first_orders['event_type_main']

user_profile = user_profile.reset_index()

# Бинарные признаки
user_profile['is_two'] = (user_profile['total_orders'] >= 2).astype(int)
user_profile['is_five'] = (user_profile['total_orders'] >= 5).astype(int)

# Проверка результатов
display(f"\nПрофиль создан для {len(user_profile)} пользователей")
display(f"\nКолонки профиля: {user_profile.columns.tolist()}")
display(f"\nПервые 5 пользователей:")
pd.set_option('display.max_columns', None)
display(user_profile.head())

display(f"\nСтатистика по профилю:")
display(user_profile[['total_orders', 'avg_revenue', 'avg_tickets', 'avg_days_between']].describe())

display(f"\nРаспределение по бинарным признакам:")
display(f"is_two (≥2 заказа): {user_profile['is_two'].sum()} ({user_profile['is_two'].sum()/len(user_profile)*100:.1f}%)")
display(f"is_five (≥5 заказов): {user_profile['is_five'].sum()} ({user_profile['is_five'].sum()/len(user_profile)*100:.1f}%)")

display(f"\nПопулярные регионы первого заказа:")
display(user_profile['first_order_region'].value_counts().head(10))

display(f"\nПопулярные жанры первого заказа:")
display(user_profile['first_order_genre'].value_counts().head(10))

# Сохраняем профиль
user_profile.to_csv('user_profile.csv', index=False)

# Основные показатели
total_users = len(user_profile)
avg_revenue_per_order = user_profile['avg_revenue'].mean()
users_two_or_more = user_profile['is_two'].mean() * 100
users_five_or_more = user_profile['is_five'].mean() * 100

# СТАТИСТИЧЕСКИЕ ПОКАЗАТЕЛИ:

# Статистика по ключевым метрикам
metrics = {
    'total_orders': 'Общее число заказов',
    'avg_tickets': 'Среднее число билетов в заказе',
    'avg_days_between': 'Среднее время между покупками (дни)'
}

for col, description in metrics.items():
    display(f"\n   {description}:")
    stats = user_profile[col].describe()
    display(f"      Минимум: {stats['min']:.2f}")
    display(f"      Медиана: {stats['50%']:.2f}")
    display(f"      Среднее: {stats['mean']:.2f}")
    display(f"      Максимум: {stats['max']:.2f}")
    display(f"      Стандартное отклонение: {stats['std']:.2f}")
    
    # Проверка на выбросы через IQR
    Q1 = stats['25%']
    Q3 = stats['75%']
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    outliers = user_profile[(user_profile[col] < lower_bound) | (user_profile[col] > upper_bound)]
    display(f"      Выбросов (IQR метод): {len(outliers)} ({len(outliers)/total_users*100:.1f}%)")

# АНАЛИЗ ВЫБРОСОВ:

# Подробный анализ выбросов для каждой метрики
display("\n   А. total_orders (число заказов):")
orders_stats = user_profile['total_orders'].describe(percentiles=[0.5, 0.75, 0.9, 0.95, 0.99, 0.999])
display(f"      99-й перцентиль: {orders_stats['99%']:.0f}")
display(f"      99.9-й перцентиль: {orders_stats['99.9%']:.0f}")
display(f"      Максимум: {orders_stats['max']:.0f}")

# Пользователи с очень большим числом заказов
high_orders = user_profile[user_profile['total_orders'] > orders_stats['99%']]
display(f"      Пользователей >99% ({orders_stats['99%']:.0f} заказов): {len(high_orders)}")

display("\n   Б. avg_tickets (среднее число билетов):")
tickets_stats = user_profile['avg_tickets'].describe(percentiles=[0.95, 0.99, 0.999])
display(f"      95-й перцентиль: {tickets_stats['95%']:.2f}")
display(f"      99-й перцентиль: {tickets_stats['99%']:.2f}")
display(f"      Максимум: {tickets_stats['max']:.2f}")

# Пользователи с аномальным средним числом билетов
high_tickets = user_profile[user_profile['avg_tickets'] > tickets_stats['99%']]
display(f"      Пользователей >99% ({tickets_stats['99%']:.2f} билетов): {len(high_tickets)}")

display("\n   В. avg_days_between (время между покупками):")
days_stats = user_profile['avg_days_between'].describe(percentiles=[0.95, 0.99])
display(f"      95-й перцентиль: {days_stats['95%']:.2f} дней")
display(f"      99-й перцентиль: {days_stats['99%']:.2f} дней")
display(f"      Максимум: {days_stats['max']:.2f} дней")

# РЕКОМЕНДАЦИИ ПО ОБРАБОТКЕ

# Решение: фильтрация по 99 перцентилю для total_orders
filter_threshold = orders_stats['99%']
users_to_keep = user_profile[user_profile['total_orders'] <= filter_threshold]
users_filtered = user_profile[user_profile['total_orders'] > filter_threshold]

display(f"\n   Предлагаемая фильтрация: удалить пользователей с >{filter_threshold:.0f} заказов (99-й перцентиль)")
display(f"   Будет удалено: {len(users_filtered)} пользователей ({len(users_filtered)/total_users*100:.1f}%)")
display(f"   Останется: {len(users_to_keep)} пользователей")

display("СТАТИСТИКА ПОСЛЕ ФИЛЬТРАЦИИ:")

if len(users_filtered) > 0:
    display(f"\n   Удаляемые пользователи (аномалии):")
    display(users_filtered[['user_id', 'total_orders', 'avg_revenue', 'avg_tickets']].sort_values('total_orders', ascending=False).head())
    
    # Обновленная статистика
    display(f"\n   Обновленные показатели после фильтрации:")
    display(f"   • Общее число пользователей: {len(users_to_keep)}")
    display(f"   • Средняя выручка: {users_to_keep['avg_revenue'].mean():.2f} руб")
    display(f"   • Доля 2+ заказов: {users_to_keep['is_two'].mean()*100:.1f}%")
    display(f"   • Доля 5+ заказов: {users_to_keep['is_five'].mean()*100:.1f}%")
    display(f"   • Максимум заказов: {users_to_keep['total_orders'].max()}")
    
    # Обновляем профиль
    user_profile_clean = users_to_keep.copy()
    
    display("\n   Сравнение до и после:")
    comparison = pd.DataFrame({
        'Показатель': ['Пользователи', 'Ср. выручка', 'Доля 2+', 'Макс. заказов'],
        'До фильтрации': [total_users, f"{avg_revenue_per_order:.2f}", f"{users_two_or_more:.1f}%", f"{orders_stats['max']:.0f}"],
        'После фильтрации': [len(user_profile_clean), f"{user_profile_clean['avg_revenue'].mean():.2f}", 
                             f"{user_profile_clean['is_two'].mean()*100:.1f}%", 
                             f"{user_profile_clean['total_orders'].max():.0f}"]
    })
    display(comparison.to_string(index=False))
else:
    display("\n   Фильтрация не требуется - аномалий нет")
    user_profile_clean = user_profile.copy()


# Сохраняем очищенный профиль
user_profile_clean.to_csv('user_profile_clean.csv', index=False)

# АНАЛИЗ ПРИЗНАКОВ ПЕРВОГО ЗАКАЗА 

# Распределение по типу первого мероприятия
genre_dist = user_profile['first_order_genre'].value_counts()
genre_percent = (genre_dist / len(user_profile) * 100).round(1)

display("\n1. РАСПРЕДЕЛЕНИЕ ПО ТИПУ ПЕРВОГО МЕРОПРИЯТИЯ:")
display(genre_dist)
display(f"Доли (%): {genre_percent.to_dict()}")

# Визуализация
plt.figure(figsize=(10, 5))
plt.bar(genre_dist.index, genre_dist.values)
plt.title('Распределение по типу первого мероприятия')
plt.xlabel('Тип мероприятия')
plt.ylabel('Количество пользователей')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Распределение по типу устройства
device_dist = user_profile['first_order_device'].value_counts()
device_percent = (device_dist / len(user_profile) * 100).round(1)

display("\n2. РАСПРЕДЕЛЕНИЕ ПО ТИПУ УСТРОЙСТВА:")
display(device_dist)
display(f"Доли (%): {device_percent.to_dict()}")

plt.figure(figsize=(8, 5))
plt.bar(device_dist.index, device_dist.values)
plt.title('Распределение по типу устройства первого заказа')
plt.xlabel('Тип устройства')
plt.ylabel('Количество пользователей')
plt.tight_layout()
plt.show()

# Распределение по региону
region_dist = user_profile['first_order_region'].value_counts()
region_percent = (region_dist / len(user_profile) * 100).round(1)

display("\n3. РАСПРЕДЕЛЕНИЕ ПО РЕГИОНУ (ТОП-10):")
display(region_dist.head(10))
display(f"Доля топ-10 регионов: {region_percent.head(10).sum():.1f}%")

plt.figure(figsize=(12, 5))
plt.bar(region_dist.head(10).index, region_dist.head(10).values)
plt.title('Топ-10 регионов по первому заказу')
plt.xlabel('Регион')
plt.ylabel('Количество пользователей')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Распределение по билетному оператору
partner_dist = user_profile['first_order_partner'].value_counts()
partner_percent = (partner_dist / len(user_profile) * 100).round(1)

display("\n4. РАСПРЕДЕЛЕНИЕ ПО БИЛЕТНОМУ ОПЕРАТОРУ:")
display(partner_dist.head(10) if len(partner_dist) > 10 else partner_dist)
display(f"Всего операторов: {len(partner_dist)}")

plt.figure(figsize=(10, 5))
n_to_show = min(15, len(partner_dist))
plt.bar(partner_dist.head(n_to_show).index, partner_dist.head(n_to_show).values)
plt.title(f'Распределение по билетному оператору (показано {n_to_show})')
plt.xlabel('Оператор')
plt.ylabel('Количество пользователей')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Анализ равномерности распределения

display(f"Всего пользователей: {len(user_profile)}")

dist_summary = pd.DataFrame({
    'Признак': ['Тип мероприятия', 'Тип устройства', 'Регион', 'Билетный оператор'],
    'Уникальных значений': [
        genre_dist.nunique(),
        device_dist.nunique(),
        region_dist.nunique(),
        partner_dist.nunique()
    ],
    'Доля крупнейшего, %': [
        genre_percent.iloc[0],
        device_percent.iloc[0],
        region_percent.iloc[0],
        partner_percent.iloc[0]
    ],
    'Топ-1 значение': [
        genre_dist.index[0],
        device_dist.index[0],
        region_dist.index[0],
        partner_dist.index[0]
    ],
    'Топ-3 доля, %': [
        genre_percent.head(3).sum(),
        device_percent.head(3).sum(),
        region_percent.head(3).sum(),
        partner_percent.head(3).sum()
    ]
})

display(dist_summary.to_string(index=False))

# АНАЛИЗ ВОЗВРАТОВ ПОЛЬЗОВАТЕЛЕЙ 

# Функция для анализа возвратов по сегментам
def analyze_returns_by_segment(data, segment_col, segment_name, top_n=10):
    """Анализирует долю возвратов по сегментам"""
    
    # Подсчет общего количества пользователей и возвратов по сегментам
    segment_analysis = data.groupby(segment_col).agg(
        total_users=('user_id', 'count'),
        returning_users=('is_two', 'sum')
    ).reset_index()
    
    # Расчет доли возвратов
    segment_analysis['return_rate'] = (segment_analysis['returning_users'] / segment_analysis['total_users'] * 100).round(1)
    
    # Средняя доля возвратов по всей выборке
    overall_return_rate = data['is_two'].mean() * 100
    
    # Сортировка
    if len(segment_analysis) > top_n:
        # Для визуализации берем топ-N по количеству пользователей
        top_segments = segment_analysis.nlargest(top_n, 'total_users')
        display(f"\n{segment_name} (топ-{top_n} по размеру сегмента):")
    else:
        top_segments = segment_analysis.sort_values('total_users', ascending=False)
        display(f"\n{segment_name}:")
    
    display(f"Средняя доля возвратов по выборке: {overall_return_rate:.1f}%")
    display(top_segments[['total_users', 'returning_users', 'return_rate']].to_string(index=False))
    
    return segment_analysis, top_segments, overall_return_rate

# Анализ по типу мероприятия
genre_analysis, top_genres, overall_rate = analyze_returns_by_segment(
    user_profile, 'first_order_genre', 'ТИП МЕРОПРИЯТИЯ'
)

# Визуализация для типов мероприятий
plt.figure(figsize=(12, 6))
bars = plt.bar(range(len(top_genres)), top_genres['return_rate'])
plt.axhline(y=overall_rate, color='r', linestyle='--', label=f'Среднее: {overall_rate:.1f}%')

plt.title('Доля возвратов по типу первого мероприятия', fontsize=14)
plt.xlabel('Тип мероприятия', fontsize=12)
plt.ylabel('Доля возвратов, %', fontsize=12)
plt.xticks(range(len(top_genres)), top_genres['first_order_genre'], rotation=45, ha='right')
plt.legend()

# Добавляем значения на столбцы и размер сегмента
for i, (bar, row) in enumerate(zip(bars, top_genres.itertuples())):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
             f'{row.return_rate}%', ha='center', va='bottom', fontsize=10)
    plt.text(bar.get_x() + bar.get_width()/2, 2, 
             f'n={row.total_users}', ha='center', va='bottom', fontsize=9, color='gray')

plt.tight_layout()
plt.show()

# Анализ по типу устройства
device_analysis, top_devices, _ = analyze_returns_by_segment(
    user_profile, 'first_order_device', 'ТИП УСТРОЙСТВА'
)

# Визуализация для типов устройств
plt.figure(figsize=(8, 6))
bars = plt.bar(range(len(top_devices)), top_devices['return_rate'])
plt.axhline(y=overall_rate, color='r', linestyle='--', label=f'Среднее: {overall_rate:.1f}%')

plt.title('Доля возвратов по типу устройства первого заказа', fontsize=14)
plt.xlabel('Тип устройства', fontsize=12)
plt.ylabel('Доля возвратов, %', fontsize=12)
plt.xticks(range(len(top_devices)), top_devices['first_order_device'])
plt.legend()

# Добавляем значения на столбцы
for i, (bar, row) in enumerate(zip(bars, top_devices.itertuples())):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
             f'{row.return_rate}%', ha='center', va='bottom', fontsize=10)
    plt.text(bar.get_x() + bar.get_width()/2, 2, 
             f'n={row.total_users}', ha='center', va='bottom', fontsize=9, color='gray')

plt.tight_layout()
plt.show()

# Анализ по региону (только топ-10)
region_analysis, top_regions, _ = analyze_returns_by_segment(
    user_profile, 'first_order_region', 'РЕГИОН', top_n=10
)

# Визуализация для регионов
plt.figure(figsize=(14, 6))
bars = plt.bar(range(len(top_regions)), top_regions['return_rate'])
plt.axhline(y=overall_rate, color='r', linestyle='--', label=f'Среднее: {overall_rate:.1f}%')

plt.title('Доля возвратов по региону первого заказа (топ-10)', fontsize=14)
plt.xlabel('Регион', fontsize=12)
plt.ylabel('Доля возвратов, %', fontsize=12)
plt.xticks(range(len(top_regions)), top_regions['first_order_region'], rotation=45, ha='right')
plt.legend()

# Добавляем значения на столбцы
for i, (bar, row) in enumerate(zip(bars, top_regions.itertuples())):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
             f'{row.return_rate}%', ha='center', va='bottom', fontsize=9)
    plt.text(bar.get_x() + bar.get_width()/2, 2, 
             f'n={row.total_users}', ha='center', va='bottom', fontsize=8, color='gray')

plt.tight_layout()
plt.show()

# Анализ по билетному оператору (только топ-10)
partner_analysis, top_partners, _ = analyze_returns_by_segment(
    user_profile, 'first_order_partner', 'БИЛЕТНЫЙ ОПЕРАТОР', top_n=10
)

# Визуализация для операторов
plt.figure(figsize=(14, 6))
bars = plt.bar(range(len(top_partners)), top_partners['return_rate'])
plt.axhline(y=overall_rate, color='r', linestyle='--', label=f'Среднее: {overall_rate:.1f}%')

plt.title('Доля возвратов по билетному оператору первого заказа (топ-10)', fontsize=14)
plt.xlabel('Оператор', fontsize=12)
plt.ylabel('Доля возвратов, %', fontsize=12)
plt.xticks(range(len(top_partners)), top_partners['first_order_partner'], rotation=45, ha='right')
plt.legend()

# Добавляем значения на столбцы
for i, (bar, row) in enumerate(zip(bars, top_partners.itertuples())):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
             f'{row.return_rate}%', ha='center', va='bottom', fontsize=9)
    plt.text(bar.get_x() + bar.get_width()/2, 2, 
             f'n={row.total_users}', ha='center', va='bottom', fontsize=8, color='gray')

plt.tight_layout()
plt.show()

# Статистический анализ - находим сегменты с наивысшей долей возвратов

# Фильтруем сегменты с достаточным размером (минимум 100 пользователей)
min_users = 100

for segment_col, segment_name in [
    ('first_order_genre', 'Тип мероприятия'),
    ('first_order_device', 'Тип устройства'),
    ('first_order_region', 'Регион'),
    ('first_order_partner', 'Билетный оператор')
]:
    segment_stats = user_profile.groupby(segment_col).agg(
        total_users=('user_id', 'count'),
        return_rate=('is_two', 'mean')
    ).reset_index()
    
    # Отбираем сегменты с достаточным размером
    large_segments = segment_stats[segment_stats['total_users'] >= min_users]
    
    if len(large_segments) > 0:
        # Находим топ-3 по доле возвратов
        top_return_segments = large_segments.nlargest(3, 'return_rate')
        
        display(f"\n{segment_name} (сегменты с ≥{min_users} пользователей):")
        for _, row in top_return_segments.iterrows():
            above_avg = "ВЫШЕ" if row['return_rate'] * 100 > overall_rate else "НИЖЕ"
            display(f"  • {row[segment_col]}: {row['return_rate']*100:.1f}% возвратов "
                  f"(пользователей: {row['total_users']}) - {above_avg} среднего")

# Анализ самых успешных "точек входа"

display("(сегменты с наибольшим числом пользователей и высокой долей возвратов)")

# Определяем критерии успешности:
# 1. Большой размер сегмента (топ-25% по количеству пользователей)
# 2. Доля возвратов выше среднего

for segment_col, segment_name in [
    ('first_order_genre', 'Тип мероприятия'),
    ('first_order_device', 'Тип устройства')
]:
    segment_stats = user_profile.groupby(segment_col).agg(
        total_users=('user_id', 'count'),
        return_rate=('is_two', 'mean')
    ).reset_index()
    
    # Критерий 1: топ-25% по размеру
    size_threshold = segment_stats['total_users'].quantile(0.75)
    # Критерий 2: выше среднего по возвратам
    return_threshold = overall_rate / 100
    
    successful_segments = segment_stats[
        (segment_stats['total_users'] >= size_threshold) &
        (segment_stats['return_rate'] >= return_threshold)
    ]
    
    if len(successful_segments) > 0:
        display(f"\n{segment_name}:")
        display(f"  Критерии: ≥{size_threshold:.0f} пользователей, ≥{overall_rate:.1f}% возвратов")
        for _, row in successful_segments.sort_values('return_rate', ascending=False).iterrows():
            display(f"  • {row[segment_col]}: {row['total_users']} пользователей, "
                  f"{row['return_rate']*100:.1f}% возвратов")
    else:
        display(f"\n{segment_name}: нет сегментов, удовлетворяющих критериям")

# ПРОВЕРКА ПРОДУКТОВЫХ ГИПОТЕЗ 

# Гипотеза 1: Тип мероприятия влияет на вероятность возврата
display("\nГИПОТЕЗА 1: Тип мероприятия влияет на вероятность возврата")

# Выбираем данные для спортивных мероприятий и концертов
sport_users = user_profile[user_profile['first_order_genre'] == 'спорт']
concert_users = user_profile[user_profile['first_order_genre'] == 'концерты']

# Статистика
sport_stats = {
    'users': len(sport_users),
    'return_rate': sport_users['is_two'].mean() * 100,
    'avg_orders': sport_users['total_orders'].mean(),
    'avg_revenue': sport_users['avg_revenue'].mean()
}

concert_stats = {
    'users': len(concert_users),
    'return_rate': concert_users['is_two'].mean() * 100,
    'avg_orders': concert_users['total_orders'].mean(),
    'avg_revenue': concert_users['avg_revenue'].mean()
}

# Таблица сравнения
comparison_df = pd.DataFrame({
    'Показатель': ['Количество пользователей', 'Доля возвратов, %', 'Среднее число заказов', 'Средняя выручка за заказ, руб'],
    'Спорт': [
        sport_stats['users'],
        f"{sport_stats['return_rate']:.1f}",
        f"{sport_stats['avg_orders']:.2f}",
        f"{sport_stats['avg_revenue']:.2f}"
    ],
    'Концерты': [
        concert_stats['users'],
        f"{concert_stats['return_rate']:.1f}",
        f"{concert_stats['avg_orders']:.2f}",
        f"{concert_stats['avg_revenue']:.2f}"
    ]
})

display(comparison_df.to_string(index=False))

# Статистическая проверка (t-тест)
from scipy import stats

sport_returns = sport_users['is_two'].values
concert_returns = concert_users['is_two'].values

t_stat, p_value = stats.ttest_ind(sport_returns, concert_returns, equal_var=False)

display(f"\nt-статистика: {t_stat:.3f}")
display(f"p-value: {p_value:.4f}")
display(f"Разница в долях возвратов: {sport_stats['return_rate'] - concert_stats['return_rate']:.1f}%")

# Визуализация для гипотезы 1
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# График 1: Доля возвратов по типам мероприятий
genres_to_compare = ['спорт', 'концерты', 'театр', 'другое', 'стендап']
return_rates = []
for genre in genres_to_compare:
    genre_users = user_profile[user_profile['first_order_genre'] == genre]
    if len(genre_users) > 0:
        return_rates.append(genre_users['is_two'].mean() * 100)

axes[0].bar(genres_to_compare, return_rates)
axes[0].axhline(y=user_profile['is_two'].mean() * 100, color='r', linestyle='--', alpha=0.7)
for i, (genre, rate) in enumerate(zip(genres_to_compare, return_rates)):
    axes[0].text(i, rate + 0.5, f'{rate:.1f}%', ha='center', va='bottom')
axes[0].set_title('Доля возвратов по типам мероприятий')
axes[0].set_xlabel('Тип мероприятия')
axes[0].set_ylabel('Доля возвратов, %')

# График 2: Сравнение спорта и концертов
categories = ['Спорт', 'Концерты']
return_rates_compare = [sport_stats['return_rate'], concert_stats['return_rate']]
user_counts = [sport_stats['users'], concert_stats['users']]

x = range(len(categories))
width = 0.35

bars1 = axes[1].bar(x, return_rates_compare, width, label='Доля возвратов')
axes[1].set_xlabel('Тип мероприятия')
axes[1].set_ylabel('Доля возвратов, %', color='tab:blue')
axes[1].tick_params(axis='y', labelcolor='tab:blue')
axes[1].set_xticks(x)
axes[1].set_xticklabels(categories)

axes2 = axes[1].twinx()
bars2 = axes2.bar([i + width for i in x], user_counts, width, color='tab:orange', label='Кол-во пользователей')
axes2.set_ylabel('Количество пользователей', color='tab:orange')
axes2.tick_params(axis='y', labelcolor='tab:orange')

axes[1].set_title('Сравнение: Спорт vs Концерты')
axes[1].legend([bars1, bars2], ['Доля возвратов', 'Кол-во пользователей'], loc='upper left')

plt.tight_layout()
plt.show()

# Гипотеза 2: Регионы с большим числом пользователей имеют более высокую долю возвратов
display("\nГИПОТЕЗА 2: В активных регионах выше доля повторных заказов")

# Анализируем связь между размером региона и долей возвратов
region_analysis = user_profile.groupby('first_order_region').agg(
    total_users=('user_id', 'count'),
    return_rate=('is_two', 'mean'),
    avg_orders=('total_orders', 'mean'),
    avg_revenue=('avg_revenue', 'mean')
).reset_index()

# Категоризируем регионы по размеру
region_analysis['size_category'] = pd.qcut(region_analysis['total_users'], 
                                          q=3, 
                                          labels=['Малые', 'Средние', 'Крупные'])

# Анализ по категориям размеров
size_analysis = region_analysis.groupby('size_category').agg(
    num_regions=('first_order_region', 'count'),
    avg_users=('total_users', 'mean'),
    avg_return_rate=('return_rate', 'mean'),
    median_return_rate=('return_rate', 'median')
).reset_index()

print(size_analysis.to_string(index=False))

# Визуализация для гипотезы 2
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# График 1: Доля возвратов по размеру регионов
axes[0].bar(size_analysis['size_category'], size_analysis['avg_return_rate'] * 100)
axes[0].axhline(y=user_profile['is_two'].mean() * 100, color='r', linestyle='--', alpha=0.7)
for i, (category, rate) in enumerate(zip(size_analysis['size_category'], size_analysis['avg_return_rate'])):
    axes[0].text(i, rate * 100 + 0.2, f'{rate*100:.1f}%', ha='center', va='bottom')
axes[0].set_title('Доля возвратов по размеру регионов')
axes[0].set_xlabel('Категория размера региона')
axes[0].set_ylabel('Доля возвратов, %')

# График 2: Диаграмма рассеяния - размер региона vs доля возвратов
axes[1].scatter(region_analysis['total_users'], region_analysis['return_rate'] * 100, alpha=0.6)
axes[1].set_xlabel('Количество пользователей в регионе')
axes[1].set_ylabel('Доля возвратов, %')
axes[1].set_title('Зависимость доли возвратов от размера региона')

# Линейная регрессия
from sklearn.linear_model import LinearRegression
X = region_analysis['total_users'].values.reshape(-1, 1)
y = region_analysis['return_rate'].values * 100
model = LinearRegression().fit(X, y)
x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
y_pred = model.predict(x_range)
axes[1].plot(x_range, y_pred, color='red', linewidth=2)

# Коэффициент корреляции
corr_coef = np.corrcoef(region_analysis['total_users'], region_analysis['return_rate'])[0, 1]
axes[1].text(0.05, 0.95, f'Коэффициент корреляции: {corr_coef:.3f}', 
             transform=axes[1].transAxes, fontsize=10, 
             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.show()

# Анализ топ-5 крупнейших регионов
print("\nТоп-5 крупнейших регионов:")
top_5_regions = region_analysis.nlargest(5, 'total_users')[['first_order_region', 'total_users', 'return_rate']]
top_5_regions['return_rate'] = (top_5_regions['return_rate'] * 100).round(1)
print(top_5_regions.to_string(index=False))

# Сравнение с общей средней
overall_return_rate = user_profile['is_two'].mean() * 100
print(f"\nОбщая средняя доля возвратов: {overall_return_rate:.1f}%")
print(f"Средняя доля возвратов в топ-5 регионах: {top_5_regions['return_rate'].mean():.1f}%")

# АНАЛИЗ СВЯЗИ МЕЖДУ ВЫРУЧКОЙ И ПОВТОРНЫМИ ЗАКАЗАМИ 

# Разделяем пользователей на две группы
single_order_users = user_profile[user_profile['total_orders'] == 1]
returning_users = user_profile[user_profile['total_orders'] >= 2]

display(f"Пользователей с одним заказом: {len(single_order_users)}")
display(f"Пользователей с 2+ заказами: {len(returning_users)}")

# Статистика по выручке
display("\nСтатистика по средней выручке за заказ:")
display("Один заказ:")
display(single_order_users['avg_revenue'].describe())
display("\n2+ заказов:")
display(returning_users['avg_revenue'].describe())

# Сравнительные гистограммы
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Определяем общие границы для гистограмм
all_revenue = user_profile['avg_revenue']
revenue_min = all_revenue.min()
revenue_max = all_revenue.max()
bins = 50

# Гистограмма 1: Сравнительное распределение
axes[0].hist(single_order_users['avg_revenue'], bins=bins, alpha=0.6, label='Один заказ', 
             density=True, color='blue', edgecolor='black')
axes[0].hist(returning_users['avg_revenue'], bins=bins, alpha=0.6, label='2+ заказов', 
             density=True, color='orange', edgecolor='black')
axes[0].set_xlabel('Средняя выручка за заказ, руб')
axes[0].set_ylabel('Плотность распределения')
axes[0].set_title('Сравнение распределения средней выручки')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Добавляем вертикальные линии для медиан
median_single = single_order_users['avg_revenue'].median()
median_returning = returning_users['avg_revenue'].median()
axes[0].axvline(median_single, color='blue', linestyle='--', alpha=0.8, linewidth=1.5)
axes[0].axvline(median_returning, color='orange', linestyle='--', alpha=0.8, linewidth=1.5)
axes[0].text(median_single, axes[0].get_ylim()[1]*0.9, f'Медиана: {median_single:.0f} руб', 
             color='blue', ha='center', fontsize=9)
axes[0].text(median_returning, axes[0].get_ylim()[1]*0.8, f'Медиана: {median_returning:.0f} руб', 
             color='orange', ha='center', fontsize=9)

# Гистограмма 2: Кумулятивное распределение
# Сортируем значения для построения CDF
sorted_single = np.sort(single_order_users['avg_revenue'])
sorted_returning = np.sort(returning_users['avg_revenue'])

# Создаем CDF
y_single = np.arange(1, len(sorted_single) + 1) / len(sorted_single)
y_returning = np.arange(1, len(sorted_returning) + 1) / len(sorted_returning)

axes[1].plot(sorted_single, y_single, label='Один заказ', color='blue', linewidth=2)
axes[1].plot(sorted_returning, y_returning, label='2+ заказов', color='orange', linewidth=2)
axes[1].set_xlabel('Средняя выручка за заказ, руб')
axes[1].set_ylabel('Доля пользователей')
axes[1].set_title('Кумулятивное распределение (CDF)')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

# Добавляем квантили
for quantile in [0.25, 0.5, 0.75]:
    q_single = np.percentile(sorted_single, quantile * 100)
    q_returning = np.percentile(sorted_returning, quantile * 100)
    axes[1].axvline(q_single, color='blue', linestyle=':', alpha=0.5)
    axes[1].axvline(q_returning, color='orange', linestyle=':', alpha=0.5)

plt.tight_layout()
plt.show()

# Анализ по квантилям выручки
display("\nАнализ по квантилям выручки:")

# Разделяем на квантили
user_profile['revenue_quantile'] = pd.qcut(user_profile['avg_revenue'], q=4, labels=['Q1 (низкая)', 'Q2', 'Q3', 'Q4 (высокая)'])

# Анализ возвращаемости по квантилям выручки
revenue_quantile_analysis = user_profile.groupby('revenue_quantile').agg(
    total_users=('user_id', 'count'),
    returning_users=('is_two', 'sum'),
    avg_revenue=('avg_revenue', 'mean')
).reset_index()

revenue_quantile_analysis['return_rate'] = (revenue_quantile_analysis['returning_users'] / revenue_quantile_analysis['total_users'] * 100).round(1)

display(revenue_quantile_analysis[['revenue_quantile', 'total_users', 'return_rate', 'avg_revenue']].to_string(index=False))

# Визуализация связи выручки и возвращаемости
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# График 1: Возвращаемость по квантилям выручки
axes[0].bar(revenue_quantile_analysis['revenue_quantile'], revenue_quantile_analysis['return_rate'])
axes[0].axhline(y=user_profile['is_two'].mean() * 100, color='r', linestyle='--', alpha=0.7, label='Среднее')
for i, (quantile, rate) in enumerate(zip(revenue_quantile_analysis['revenue_quantile'], revenue_quantile_analysis['return_rate'])):
    axes[0].text(i, rate + 0.5, f'{rate}%', ha='center', va='bottom')
axes[0].set_xlabel('Квантиль выручки')
axes[0].set_ylabel('Доля возвратов, %')
axes[0].set_title('Зависимость возвращаемости от средней выручки')
axes[0].legend()

# График 2: Диаграмма рассеяния
scatter = axes[1].scatter(user_profile['avg_revenue'], user_profile['total_orders'], 
                         alpha=0.3, s=20, c=user_profile['is_two'], cmap='coolwarm')
axes[1].set_xlabel('Средняя выручка за заказ, руб')
axes[1].set_ylabel('Общее количество заказов')
axes[1].set_title('Связь выручки и количества заказов')
plt.colorbar(scatter, ax=axes[1], label='Возвращаемость (0/1)')

# Добавляем линию тренда для возвращающихся пользователей
returning = user_profile[user_profile['is_two'] == 1]
if len(returning) > 0:
    from sklearn.linear_model import LinearRegression
    X = returning['avg_revenue'].values.reshape(-1, 1)
    y = returning['total_orders'].values
    model = LinearRegression().fit(X, y)
    x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
    y_pred = model.predict(x_range)
    axes[1].plot(x_range, y_pred, color='red', linewidth=2, label='Тренд (2+ заказов)')
    axes[1].legend()

plt.tight_layout()
plt.show()

# Статистическая проверка различий
display("\nСтатистическая проверка различий:")
from scipy import stats

t_stat, p_value = stats.ttest_ind(
    single_order_users['avg_revenue'].dropna(),
    returning_users['avg_revenue'].dropna(),
    equal_var=False
)

display(f"t-статистика: {t_stat:.3f}")
display(f"p-value: {p_value:.4f}")

# Эффект Коэна
def cohens_d(x, y):
    nx = len(x)
    ny = len(y)
    dof = nx + ny - 2
    return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1)**2 + (ny-1)*np.std(y, ddof=1)**2) / dof)

d = cohens_d(returning_users['avg_revenue'], single_order_users['avg_revenue'])
display(f"Эффект Коэна: {d:.3f}")

# Анализ пороговых значений
display("\nАнализ пороговых значений выручки:")
thresholds = [0, 100, 200, 300, 400, 500, 1000]
for i in range(len(thresholds)-1):
    low = thresholds[i]
    high = thresholds[i+1]
    
    segment_users = user_profile[(user_profile['avg_revenue'] >= low) & (user_profile['avg_revenue'] < high)]
    if len(segment_users) > 0:
        return_rate = segment_users['is_two'].mean() * 100
        print(f"Выручка {low}-{high} руб: {len(segment_users)} пользователей, возвращаемость {return_rate:.1f}%")

# СРАВНЕНИЕ ВЫРУЧКИ У ПОЛЬЗОВАТЕЛЕЙ С РАЗНОЙ АКТИВНОСТЬЮ

# Разделяем пользователей на две группы
group_2_4 = user_profile[(user_profile['total_orders'] >= 2) & (user_profile['total_orders'] <= 4)]
group_5_plus = user_profile[user_profile['total_orders'] >= 5]

display(f"Пользователей с 2-4 заказами: {len(group_2_4)}")
display(f"Пользователей с 5+ заказами: {len(group_5_plus)}")

# Базовая статистика
display("\nСтатистика по средней выручке за заказ:")
display("2-4 заказа:")
display(group_2_4['avg_revenue'].describe())
display("\n5+ заказов:")
display(group_5_plus['avg_revenue'].describe())

# Сравнительные визуализации
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Гистограмма 1: Сравнительное распределение
all_revenue = pd.concat([group_2_4['avg_revenue'], group_5_plus['avg_revenue']])
bins = 40

axes[0, 0].hist(group_2_4['avg_revenue'], bins=bins, alpha=0.6, label='2-4 заказа', 
               density=True, color='blue', edgecolor='black')
axes[0, 0].hist(group_5_plus['avg_revenue'], bins=bins, alpha=0.6, label='5+ заказов', 
               density=True, color='orange', edgecolor='black')
axes[0, 0].set_xlabel('Средняя выручка за заказ, руб')
axes[0, 0].set_ylabel('Плотность распределения')
axes[0, 0].set_title('Сравнение распределения средней выручки')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# Медианы
median_2_4 = group_2_4['avg_revenue'].median()
median_5_plus = group_5_plus['avg_revenue'].median()
axes[0, 0].axvline(median_2_4, color='blue', linestyle='--', alpha=0.8, linewidth=1.5)
axes[0, 0].axvline(median_5_plus, color='orange', linestyle='--', alpha=0.8, linewidth=1.5)
axes[0, 0].text(median_2_4, axes[0, 0].get_ylim()[1]*0.9, f'Медиана: {median_2_4:.0f} руб', 
               color='blue', ha='center', fontsize=9)
axes[0, 0].text(median_5_plus, axes[0, 0].get_ylim()[1]*0.8, f'Медиана: {median_5_plus:.0f} руб', 
               color='orange', ha='center', fontsize=9)

# Boxplot сравнение
box_data = [group_2_4['avg_revenue'], group_5_plus['avg_revenue']]
axes[0, 1].boxplot(box_data, labels=['2-4 заказа', '5+ заказов'])
axes[0, 1].set_ylabel('Средняя выручка за заказ, руб')
axes[0, 1].set_title('Boxplot сравнения выручки')
axes[0, 1].grid(True, alpha=0.3)

# Добавляем средние значения
means = [group_2_4['avg_revenue'].mean(), group_5_plus['avg_revenue'].mean()]
for i, mean_val in enumerate(means, 1):
    axes[0, 1].text(i, mean_val + 50, f'Среднее: {mean_val:.0f} руб', 
                   ha='center', va='bottom', fontsize=9, color='red')

# Кумулятивное распределение (CDF)
sorted_2_4 = np.sort(group_2_4['avg_revenue'])
sorted_5_plus = np.sort(group_5_plus['avg_revenue'])

y_2_4 = np.arange(1, len(sorted_2_4) + 1) / len(sorted_2_4)
y_5_plus = np.arange(1, len(sorted_5_plus) + 1) / len(sorted_5_plus)

axes[1, 0].plot(sorted_2_4, y_2_4, label='2-4 заказа', color='blue', linewidth=2)
axes[1, 0].plot(sorted_5_plus, y_5_plus, label='5+ заказов', color='orange', linewidth=2)
axes[1, 0].set_xlabel('Средняя выручка за заказ, руб')
axes[1, 0].set_ylabel('Доля пользователей')
axes[1, 0].set_title('Кумулятивное распределение (CDF)')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# Отметки квантилей
for quantile in [0.25, 0.5, 0.75, 0.9]:
    q_2_4 = np.percentile(sorted_2_4, quantile * 100)
    q_5_plus = np.percentile(sorted_5_plus, quantile * 100)
    axes[1, 0].axvline(q_2_4, color='blue', linestyle=':', alpha=0.3)
    axes[1, 0].axvline(q_5_plus, color='orange', linestyle=':', alpha=0.3)
    axes[1, 0].text(q_2_4, quantile + 0.02, f'{quantile*100:.0f}%', color='blue', fontsize=8, ha='center')
    axes[1, 0].text(q_5_plus, quantile + 0.02, f'{quantile*100:.0f}%', color='orange', fontsize=8, ha='center')

# Диаграмма рассеяния: выручка vs количество заказов
scatter = axes[1, 1].scatter(user_profile['avg_revenue'], user_profile['total_orders'], 
                           alpha=0.4, s=30, c=user_profile['is_five'], cmap='viridis')
axes[1, 1].set_xlabel('Средняя выручка за заказ, руб')
axes[1, 1].set_ylabel('Общее количество заказов')
axes[1, 1].set_title('Связь выручки и уровня активности')
plt.colorbar(scatter, ax=axes[1, 1], label='5+ заказов (0/1)')

# Линии тренда для каждой группы
if len(group_2_4) > 0 and len(group_5_plus) > 0:
    from sklearn.linear_model import LinearRegression
    
    # Для группы 2-4
    X_2_4 = group_2_4['avg_revenue'].values.reshape(-1, 1)
    y_2_4_orders = group_2_4['total_orders'].values
    if len(X_2_4) > 1:
        model_2_4 = LinearRegression().fit(X_2_4, y_2_4_orders)
        x_range = np.linspace(X_2_4.min(), X_2_4.max(), 100).reshape(-1, 1)
        y_pred_2_4 = model_2_4.predict(x_range)
        axes[1, 1].plot(x_range, y_pred_2_4, color='blue', linewidth=2, alpha=0.7, label='Тренд 2-4')
    
    # Для группы 5+
    X_5_plus = group_5_plus['avg_revenue'].values.reshape(-1, 1)
    y_5_plus_orders = group_5_plus['total_orders'].values
    if len(X_5_plus) > 1:
        model_5_plus = LinearRegression().fit(X_5_plus, y_5_plus_orders)
        x_range = np.linspace(X_5_plus.min(), X_5_plus.max(), 100).reshape(-1, 1)
        y_pred_5_plus = model_5_plus.predict(x_range)
        axes[1, 1].plot(x_range, y_pred_5_plus, color='orange', linewidth=2, alpha=0.7, label='Тренд 5+')
    
    axes[1, 1].legend()

plt.tight_layout()
plt.show()

# Статистическая проверка различий
display("\nСТАТИСТИЧЕСКАЯ ПРОВЕРКА РАЗЛИЧИЙ:")
from scipy import stats

# t-тест
t_stat, p_value = stats.ttest_ind(
    group_2_4['avg_revenue'].dropna(),
    group_5_plus['avg_revenue'].dropna(),
    equal_var=False
)

display(f"t-статистика: {t_stat:.3f}")
display(f"p-value: {p_value:.4f}")

# Эффект Коэна
def cohens_d(x, y):
    nx = len(x)
    ny = len(y)
    dof = nx + ny - 2
    return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1)**2 + (ny-1)*np.std(y, ddof=1)**2) / dof)

d = cohens_d(group_5_plus['avg_revenue'], group_2_4['avg_revenue'])
display(f"Эффект Коэна: {d:.3f}")

# Квантильный анализ
display("\nАНАЛИЗ ПО КВАНТИЛЯМ ВЫРУЧКИ:")
display("Сравнение ключевых квантилей:")

quantiles = [0.25, 0.5, 0.75, 0.9]
for q in quantiles:
    q_2_4 = group_2_4['avg_revenue'].quantile(q)
    q_5_plus = group_5_plus['avg_revenue'].quantile(q)
    diff = q_5_plus - q_2_4
    diff_pct = (diff / q_2_4 * 100) if q_2_4 > 0 else 0
    print(f"{q*100:.0f}% перцентиль: {q_2_4:.0f} руб (2-4) vs {q_5_plus:.0f} руб (5+) | "
          f"Разница: {diff:.0f} руб ({diff_pct:.1f}%)")

# Анализ по сегментам выручки
display("\nАНАЛИЗ ПО СЕГМЕНТАМ ВЫРУЧКИ:")

# Определяем сегменты
bins = [0, 200, 400, 600, 1000, 5000, float('inf')]
labels = ['0-200', '200-400', '400-600', '600-1000', '1000-5000', '5000+']

user_profile['revenue_segment'] = pd.cut(user_profile['avg_revenue'], bins=bins, labels=labels, right=False)

# Анализ по сегментам
segment_analysis = user_profile[user_profile['total_orders'] >= 2].groupby('revenue_segment').agg(
    total_users=('user_id', 'count'),
    avg_orders=('total_orders', 'mean'),
    pct_5_plus=('is_five', 'mean'),
    avg_revenue=('avg_revenue', 'mean')
).reset_index()

segment_analysis['pct_5_plus'] = (segment_analysis['pct_5_plus'] * 100).round(1)
segment_analysis['avg_orders'] = segment_analysis['avg_orders'].round(2)

display("\nЗависимость активности от сегмента выручки (только пользователи с 2+ заказами):")
display(segment_analysis.to_string(index=False))

# Манн-Уитни тест (непараметрический)
display("\nНЕПАРАМЕТРИЧЕСКИЙ ТЕСТ МАННА-УИТНИ:")
u_stat, p_mann = stats.mannwhitneyu(
    group_2_4['avg_revenue'].dropna(),
    group_5_plus['avg_revenue'].dropna(),
    alternative='two-sided'
)

display(f"U-статистика: {u_stat:.0f}")
display(f"p-value: {p_mann:.4f}")

# АНАЛИЗ ВЛИЯНИЯ КОЛИЧЕСТВА БИЛЕТОВ НА ВОЗВРАЩАЕМОСТЬ 

# Распределение пользователей по среднему количеству билетов
display("\nОбщая статистика по количеству билетов:")
display(user_profile['avg_tickets'].describe())

# Разделение на сегменты
bins = [1, 2, 3, 5, float('inf')]
labels = ['1-2 билета', '2-3 билета', '3-5 билетов', '5+ билетов']

user_profile['tickets_segment'] = pd.cut(user_profile['avg_tickets'], bins=bins, labels=labels, right=False)

# Анализ по сегментам
segment_analysis = user_profile.groupby('tickets_segment').agg(
    total_users=('user_id', 'count'),
    returning_users=('is_two', 'sum'),
    avg_tickets=('avg_tickets', 'mean'),
    avg_revenue=('avg_revenue', 'mean')
).reset_index()

segment_analysis['return_rate'] = (segment_analysis['returning_users'] / segment_analysis['total_users'] * 100).round(1)
segment_analysis['user_share'] = (segment_analysis['total_users'] / len(user_profile) * 100).round(1)

display("\nАнализ по сегментам количества билетов:")
display(segment_analysis[['tickets_segment', 'total_users', 'user_share', 'return_rate', 
                       'avg_tickets', 'avg_revenue']].to_string(index=False))

# Визуализация
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# Распределение по сегментам
axes[0].bar(segment_analysis['tickets_segment'], segment_analysis['user_share'])
axes[0].set_xlabel('Сегмент по количеству билетов')
axes[0].set_ylabel('Доля пользователей, %')
axes[0].set_title('Распределение пользователей по сегментам')
for i, share in enumerate(segment_analysis['user_share']):
    axes[0].text(i, share + 1, f'{share}%', ha='center', va='bottom')

# Доля возвратов по сегментам
axes[1].bar(segment_analysis['tickets_segment'], segment_analysis['return_rate'])
axes[1].axhline(y=user_profile['is_two'].mean() * 100, color='r', linestyle='--', 
               label=f'Среднее: {user_profile["is_two"].mean()*100:.1f}%')
axes[1].set_xlabel('Сегмент по количеству билетов')
axes[1].set_ylabel('Доля возвратов, %')
axes[1].set_title('Доля возвратов по сегментам')
axes[1].legend()
for i, rate in enumerate(segment_analysis['return_rate']):
    axes[1].text(i, rate + 0.5, f'{rate}%', ha='center', va='bottom')

# Средняя выручка по сегментам
axes[2].bar(segment_analysis['tickets_segment'], segment_analysis['avg_revenue'])
axes[2].set_xlabel('Сегмент по количеству билетов')
axes[2].set_ylabel('Средняя выручка, руб')
axes[2].set_title('Средняя выручка по сегментам')
for i, revenue in enumerate(segment_analysis['avg_revenue']):
    axes[2].text(i, revenue + 20, f'{revenue:.0f} руб', ha='center', va='bottom')

plt.tight_layout()
plt.show()

# Статистический анализ
display("\nСтатистическая проверка различий:")
overall_return_rate = user_profile['is_two'].mean() * 100

for segment in labels:
    segment_data = user_profile[user_profile['tickets_segment'] == segment]
    segment_rate = segment_data['is_two'].mean() * 100
    diff = segment_rate - overall_return_rate
    
    # Z-тест для пропорций
    n = len(segment_data)
    z_score = (segment_rate/100 - overall_return_rate/100) / np.sqrt((overall_return_rate/100)*(1-overall_return_rate/100)/n)
    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))
    
    significant = "ДА" if p_value < 0.05 else "НЕТ"
    print(f"{segment}: {segment_rate:.1f}% возвратов (разница: {diff:+.1f}%) | "
          f"Стат. значимо: {significant} (p={p_value:.4f})")

# АНАЛИЗ ВЛИЯНИЯ КОЛИЧЕСТВА БИЛЕТОВ НА ВОЗВРАЩАЕМОСТЬ 

# 1. Общий анализ распределения
print("\n1. ОБЩАЯ СТАТИСТИКА ПО СРЕДНЕМУ КОЛИЧЕСТВУ БИЛЕТОВ:")
print(user_profile['avg_tickets'].describe())

# Визуализация общего распределения
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Гистограмма распределения
axes[0].hist(user_profile['avg_tickets'], bins=30, edgecolor='black', alpha=0.7)
axes[0].set_xlabel('Среднее количество билетов в заказе')
axes[0].set_ylabel('Количество пользователей')
axes[0].set_title('Распределение пользователей по среднему количеству билетов')
axes[0].grid(True, alpha=0.3)

# Добавляем вертикальные линии для ключевых значений
mean_val = user_profile['avg_tickets'].mean()
median_val = user_profile['avg_tickets'].median()
axes[0].axvline(mean_val, color='red', linestyle='--', label=f'Среднее: {mean_val:.2f}')
axes[0].axvline(median_val, color='green', linestyle='--', label=f'Медиана: {median_val:.2f}')
axes[0].legend()

# Boxplot
axes[1].boxplot(user_profile['avg_tickets'], vert=False)
axes[1].set_xlabel('Среднее количество билетов в заказе')
axes[1].set_title('Boxplot среднего количества билетов')
axes[1].grid(True, alpha=0.3)

# Добавляем статистику
stats_text = f"""
Мин: {user_profile['avg_tickets'].min():.1f}
25%: {user_profile['avg_tickets'].quantile(0.25):.1f}
Медиана: {median_val:.1f}
75%: {user_profile['avg_tickets'].quantile(0.75):.1f}
Макс: {user_profile['avg_tickets'].max():.1f}
"""
axes[1].text(0.05, 0.95, stats_text, transform=axes[1].transAxes, fontsize=10,
             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.show()

# 2. Разделение на сегменты
print("\n2. РАЗДЕЛЕНИЕ НА СЕГМЕНТЫ ПО КОЛИЧЕСТВУ БИЛЕТОВ:")

# Определяем сегменты
bins = [1, 2, 3, 5, float('inf')]
labels = ['1-2 билета', '2-3 билета', '3-5 билетов', '5+ билетов']

user_profile['tickets_segment'] = pd.cut(user_profile['avg_tickets'], bins=bins, labels=labels, right=False)

# Анализ по сегментам
segment_analysis = user_profile.groupby('tickets_segment').agg(
    total_users=('user_id', 'count'),
    returning_users=('is_two', 'sum'),
    avg_tickets=('avg_tickets', 'mean'),
    avg_revenue=('avg_revenue', 'mean')
).reset_index()

segment_analysis['return_rate'] = (segment_analysis['returning_users'] / segment_analysis['total_users'] * 100).round(1)
segment_analysis['user_share'] = (segment_analysis['total_users'] / len(user_profile) * 100).round(1)

print(segment_analysis[['tickets_segment', 'total_users', 'user_share', 'return_rate', 
                       'avg_tickets', 'avg_revenue']].to_string(index=False))

# 3. Визуализация анализа сегментов
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# График 1: Распределение пользователей по сегментам
axes[0].bar(segment_analysis['tickets_segment'], segment_analysis['user_share'])
axes[0].set_xlabel('Сегмент по количеству билетов')
axes[0].set_ylabel('Доля пользователей, %')
axes[0].set_title('Распределение пользователей по сегментам')
axes[0].set_ylim(0, segment_analysis['user_share'].max() * 1.1)

for i, share in enumerate(segment_analysis['user_share']):
    axes[0].text(i, share + 1, f'{share}%', ha='center', va='bottom')

# График 2: Доля возвратов по сегментам
axes[1].bar(segment_analysis['tickets_segment'], segment_analysis['return_rate'])
axes[1].axhline(y=user_profile['is_two'].mean() * 100, color='r', linestyle='--', 
               label=f'Среднее: {user_profile["is_two"].mean()*100:.1f}%')
axes[1].set_xlabel('Сегмент по количеству билетов')
axes[1].set_ylabel('Доля возвратов, %')
axes[1].set_title('Доля возвратов по сегментам')
axes[1].legend()

for i, rate in enumerate(segment_analysis['return_rate']):
    axes[1].text(i, rate + 0.5, f'{rate}%', ha='center', va='bottom')

# График 3: Средняя выручка по сегментам
axes[2].bar(segment_analysis['tickets_segment'], segment_analysis['avg_revenue'])
axes[2].set_xlabel('Сегмент по количеству билетов')
axes[2].set_ylabel('Средняя выручка, руб')
axes[2].set_title('Средняя выручка по сегментам')

for i, revenue in enumerate(segment_analysis['avg_revenue']):
    axes[2].text(i, revenue + 20, f'{revenue:.0f} руб', ha='center', va='bottom')

plt.tight_layout()
plt.show()

# 4. Детальный анализ внутри каждого сегмента
print("\n3. ДЕТАЛЬНЫЙ АНАЛИЗ ВНУТРИ СЕГМЕНТОВ:")

fig, axes = plt.subplots(2, 2, figsize=(14, 10))
axes = axes.flatten()

for idx, segment in enumerate(labels):
    segment_data = user_profile[user_profile['tickets_segment'] == segment]
    
    # Разделяем на возвращающихся и нет
    returning = segment_data[segment_data['is_two'] == 1]
    non_returning = segment_data[segment_data['is_two'] == 0]
    
    # Строим гистограммы
    axes[idx].hist(non_returning['avg_tickets'], bins=20, alpha=0.6, label='Один заказ', 
                  density=True, color='blue', edgecolor='black')
    axes[idx].hist(returning['avg_tickets'], bins=20, alpha=0.6, label='2+ заказов', 
                  density=True, color='orange', edgecolor='black')
    
    axes[idx].set_xlabel('Среднее количество билетов')
    axes[idx].set_ylabel('Плотность')
    axes[idx].set_title(f'Сегмент: {segment}\n'
                       f'{len(segment_data)} пользователей, '
                       f'{len(returning)/len(segment_data)*100:.1f}% возвратов')
    axes[idx].legend()
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# 5. Статистическая проверка различий между сегментами
print("\n4. СТАТИСТИЧЕСКАЯ ПРОВЕРКА РАЗЛИЧИЙ:")

from scipy import stats

# Создаем списки данных для каждого сегмента
segment_data = {}
for segment in labels:
    segment_data[segment] = user_profile[user_profile['tickets_segment'] == segment]['is_two'].values

# Сравниваем каждый сегмент с общим средним
overall_return_rate = user_profile['is_two'].mean()
print(f"Общая средняя доля возвратов: {overall_return_rate*100:.1f}%")

print("\nСравнение сегментов с общим средним:")
for segment in labels:
    segment_return_rate = segment_analysis[segment_analysis['tickets_segment'] == segment]['return_rate'].values[0] / 100
    n = segment_analysis[segment_analysis['tickets_segment'] == segment]['total_users'].values[0]
    
    # Z-тест для пропорций
    z_score = (segment_return_rate - overall_return_rate) / np.sqrt(overall_return_rate * (1 - overall_return_rate) / n)
    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))
    
    significant = "ДА" if p_value < 0.05 else "НЕТ"
    direction = "выше" if segment_return_rate > overall_return_rate else "ниже"
    
    print(f"{segment}: {segment_return_rate*100:.1f}% возвратов ({direction} среднего) | "
          f"Z={z_score:.2f}, p={p_value:.4f} | Стат. значимо: {significant}")

# 6. Анализ связи количества билетов и выручки
print("\n5. АНАЛИЗ СВЯЗИ КОЛИЧЕСТВА БИЛЕТОВ И ВЫРУЧКИ:")

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Диаграмма рассеяния
scatter = axes[0].scatter(user_profile['avg_tickets'], user_profile['avg_revenue'], 
                         alpha=0.3, s=20, c=user_profile['is_two'], cmap='coolwarm')
axes[0].set_xlabel('Среднее количество билетов')
axes[0].set_ylabel('Средняя выручка, руб')
axes[0].set_title('Связь количества билетов и выручки')
plt.colorbar(scatter, ax=axes[0], label='Возвращаемость (0/1)')

# Линия тренда
if len(user_profile) > 0:
    X = user_profile['avg_tickets'].values.reshape(-1, 1)
    y = user_profile['avg_revenue'].values
    model = LinearRegression().fit(X, y)
    x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
    y_pred = model.predict(x_range)
    axes[0].plot(x_range, y_pred, color='red', linewidth=2, label=f'Тренд: y={model.coef_[0]:.0f}x+{model.intercept_:.0f}')
    axes[0].legend()
    
    print(f"Коэффициент корреляции: {np.corrcoef(user_profile['avg_tickets'], user_profile['avg_revenue'])[0,1]:.3f}")

# График: средняя выручка по количеству билетов (целые значения)
ticket_counts = np.arange(1, int(user_profile['avg_tickets'].max()) + 1)
avg_revenue_by_tickets = []
return_rate_by_tickets = []

for tickets in ticket_counts:
    mask = (user_profile['avg_tickets'] >= tickets - 0.5) & (user_profile['avg_tickets'] < tickets + 0.5)
    if mask.sum() > 10:  # Минимум 10 пользователей для надежности
        avg_revenue_by_tickets.append(user_profile[mask]['avg_revenue'].mean())
        return_rate_by_tickets.append(user_profile[mask]['is_two'].mean() * 100)

axes[1].plot(ticket_counts[:len(avg_revenue_by_tickets)], avg_revenue_by_tickets, 
            marker='o', label='Средняя выручка', color='blue')
axes[1].set_xlabel('Количество билетов')
axes[1].set_ylabel('Средняя выручка, руб', color='blue')
axes[1].tick_params(axis='y', labelcolor='blue')

ax2 = axes[1].twinx()
ax2.plot(ticket_counts[:len(return_rate_by_tickets)], return_rate_by_tickets, 
        marker='s', label='Доля возвратов', color='orange')
ax2.set_ylabel('Доля возвратов, %', color='orange')
ax2.tick_params(axis='y', labelcolor='orange')

axes[1].set_title('Зависимость выручки и возвращаемости от количества билетов')
lines1, labels1 = axes[1].get_legend_handles_labels()
lines2, labels2 = ax2.get_legend_handles_labels()
axes[1].legend(lines1 + lines2, labels1 + labels2, loc='upper left')

plt.tight_layout()
plt.show()

# "АНАЛИЗ ВЛИЯНИЯ ИНТЕРВАЛА МЕЖДУ ЗАКАЗАМИ"

# Группы пользователей
group_2_4 = user_profile[(user_profile['total_orders'] >= 2) & (user_profile['total_orders'] <= 4)].copy()
group_5_plus = user_profile[user_profile['total_orders'] >= 5].copy()

display(f"Пользователей с 2-4 заказами: {len(group_2_4)}")
display(f"Пользователей с 5+ заказами: {len(group_5_plus)}")

# Базовая статистика
display("\nСтатистика по интервалам (дни):")
display("2-4 заказа - Медиана:", f"{group_2_4['avg_days_between'].median():.1f}", 
      "Среднее:", f"{group_2_4['avg_days_between'].mean():.1f}")
display("5+ заказов - Медиана:", f"{group_5_plus['avg_days_between'].median():.1f}", 
      "Среднее:", f"{group_5_plus['avg_days_between'].mean():.1f}")

# Визуализация
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Boxplot
axes[0].boxplot([group_2_4['avg_days_between'], group_5_plus['avg_days_between']], 
               labels=['2-4 заказа', '5+ заказов'])
axes[0].set_ylabel('Средний интервал между заказами, дни')
axes[0].set_title('Сравнение интервалов между группами')
axes[0].grid(True, alpha=0.3)

# Гистограмма
axes[1].hist(group_2_4['avg_days_between'], bins=30, alpha=0.5, label='2-4 заказа', density=True)
axes[1].hist(group_5_plus['avg_days_between'], bins=30, alpha=0.5, label='5+ заказов', density=True)
axes[1].set_xlabel('Средний интервал между заказами, дни')
axes[1].set_ylabel('Плотность распределения')
axes[1].set_title('Распределение интервалов')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Анализ по сегментам интервалов
bins = [0, 1, 3, 7, 14, 30, float('inf')]
labels = ['<1 дня', '1-3 дня', '3-7 дней', '1-2 нед', '2-4 нед', '>1 мес']

returning_users = user_profile[user_profile['total_orders'] >= 2].copy()
returning_users['interval_segment'] = pd.cut(returning_users['avg_days_between'], bins=bins, labels=labels, right=False)

interval_analysis = returning_users.groupby('interval_segment').agg(
    total_users=('user_id', 'count'),
    avg_orders=('total_orders', 'mean'),
    pct_5_plus=('is_five', 'mean')
).reset_index()

interval_analysis['pct_5_plus'] = (interval_analysis['pct_5_plus'] * 100).round(1)
interval_analysis['user_share'] = (interval_analysis['total_users'] / len(returning_users) * 100).round(1)

display("\nАнализ по сегментам интервалов:")
display(interval_analysis[['interval_segment', 'total_users', 'user_share', 'pct_5_plus']].to_string(index=False))

# Статистический тест
from scipy import stats
t_stat, p_value = stats.ttest_ind(group_2_4['avg_days_between'].dropna(), 
                                  group_5_plus['avg_days_between'].dropna(), 
                                  equal_var=False)
print(f"\nСтатистическая проверка: t={t_stat:.2f}, p={p_value:.4f}")

# КОРРЕЛЯЦИОННЫЙ АНАЛИЗ ПРИЗНАКОВ И КОЛИЧЕСТВА ЗАКАЗОВ 

# Создаем копию данных для анализа
analysis_data = user_profile.copy()

# Создаем категориальную переменную для количества заказов
def categorize_orders(n):
    if n == 1:
        return '1 заказ'
    elif 2 <= n <= 4:
        return '2-4 заказа'
    else:
        return '5+ заказов'

analysis_data['orders_category'] = analysis_data['total_orders'].apply(categorize_orders)

# Подготовка признаков для корреляционного анализа
# Выбираем релевантные признаки
features_for_correlation = [
    # Категориальные признаки первого заказа
    'first_order_genre',
    'first_order_device', 
    'first_order_region',
    'first_order_partner',
    
    # Числовые признаки
    'avg_revenue',
    'avg_tickets',
    'avg_days_between'
]

# Устанавливаем и импортируем phik
!pip install phik -q

from phik import phik_matrix
import warnings
warnings.filterwarnings('ignore')

# Подготовка данных для phik
correlation_data = analysis_data[features_for_correlation + ['orders_category', 'total_orders']].copy()

# Расчет матрицы корреляции Phik
print("\nРасчет корреляций Phik...")
phik_overview = correlation_data.phik_matrix(interval_cols=['avg_revenue', 'avg_tickets', 'avg_days_between', 'total_orders'])

# Выбираем только корреляции с orders_category и total_orders
target_correlations = phik_overview[['orders_category', 'total_orders']].copy()
target_correlations = target_correlations.drop(['orders_category', 'total_orders'])  # Убираем самореференс

display("\nКорреляции признаков с количеством заказов:")
display(target_correlations.sort_values('total_orders', ascending=False).to_string())

# Визуализация тепловой карты
plt.figure(figsize=(10, 6))

# Создаем матрицу для визуализации
corr_matrix = phik_overview.loc[features_for_correlation + ['orders_category'], 
                               ['orders_category', 'total_orders']]

# Сортируем по корреляции с total_orders
corr_matrix = corr_matrix.sort_values('total_orders', ascending=False)

# Тепловая карта
sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', 
           center=0, linewidths=1, linecolor='black', cbar_kws={'label': 'Phi_k coefficient'})
plt.title('Корреляция признаков с количеством заказов (Phi_k)', fontsize=14)
plt.tight_layout()
plt.show()

# Детальный анализ по сегментам
display("\nАНАЛИЗ ПО СЕГМЕНТАМ АКТИВНОСТИ:")

# Распределение по сегментам
segment_counts = analysis_data['orders_category'].value_counts()
display("\nРаспределение по сегментам активности:")
for segment, count in segment_counts.items():
    print(f"{segment}: {count} пользователей ({count/len(analysis_data)*100:.1f}%)")

# Анализ средних значений по сегментам
display("\nСредние значения по сегментам:")
segment_analysis = analysis_data.groupby('orders_category').agg({
    'avg_revenue': 'mean',
    'avg_tickets': 'mean', 
    'avg_days_between': 'mean'
}).round(2)

display(segment_analysis)

# Визуализация различий по сегментам
fig, axes = plt.subplots(1, 3, figsize=(15, 4))

metrics = ['avg_revenue', 'avg_tickets', 'avg_days_between']
titles = ['Средняя выручка', 'Среднее количество билетов', 'Средний интервал между заказами']
colors = ['skyblue', 'lightcoral', 'lightgreen']

for idx, (metric, title, color) in enumerate(zip(metrics, titles, colors)):
    segment_means = analysis_data.groupby('orders_category')[metric].mean()
    
    bars = axes[idx].bar(segment_means.index, segment_means.values, color=color)
    axes[idx].set_xlabel('Сегмент активности')
    axes[idx].set_ylabel(title)
    axes[idx].set_title(f'{title} по сегментам')
    
    for bar, value in zip(bars, segment_means.values):
        axes[idx].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 
                      (bar.get_height() * 0.05), f'{value:.1f}', 
                      ha='center', va='bottom', fontsize=9)

plt.tight_layout()
plt.show()

# Анализ категориальных признаков по сегментам
display("\nРАСПРЕДЕЛЕНИЕ КАТЕГОРИАЛЬНЫХ ПРИЗНАКОВ ПО СЕГМЕНТАМ:")

categorical_features = ['first_order_genre', 'first_order_device', 'first_order_region', 'first_order_partner']

for feature in categorical_features:
    display(f"\n{feature}:")
    
    # Создаем кросс-таблицу
    crosstab = pd.crosstab(analysis_data[feature], analysis_data['orders_category'], 
                          normalize='columns') * 100
    
    # Показываем топ-5 значений для каждого сегмента
    for segment in ['1 заказ', '2-4 заказа', '5+ заказов']:
        if segment in crosstab.columns:
            top_values = crosstab[segment].nlargest(3)
            display(f"  {segment}:")
            for value, percentage in top_values.items():
                display(f"    {value}: {percentage:.1f}%")



